# 端口号 10000-20000
port:
  min: 10000
  max: 10009
#-------------------------server Setting-------------------------

server:
#  port: ${random.int[10000,10010]}
#  # 优雅关闭
  shutdown: graceful

#-------------------------spring Setting-------------------------
spring:
  #============ name
  application:
    name: netty-socket
  #-------------------------International i18n-------------------------
  messages:
    # @value
    basename: i18n/messages
    encoding: UTF-8
  #============ redis
  redis:
    host: ${REDIS_HOST:127.0.0.1}
    port: ${REDIS_PORT:6379}
    password: ${REDIS_PWD:Y)D7d%gXFsCL*&pdJ4f)}
    ssl: false          # Redis 是否启用 SSL
    timeout: 10000      # 连接超时时间
    database: 0         # 选择的数据库:Redis 默认提供 16 个数据库（索引 0 到 15）
    jedis:
      # 配置上连接池：增加对于数据连接的管理，提升访问的效率，也保证了对资源的合理利用
      pool:
        max-active: 50      # 最大活动连接数
        max-idle: 5         # 最大空闲连接数
        max-wait: 1         # 最小空闲连接数
        min-idle: 200       # 连接池最大阻塞等待时间（使用负值表示没有限制）
  #-------------------------Kafka-------------------------
  # Kafka 配置项，对应 KafkaProperties 配置类
  kafka:
    bootstrap-servers: 127.0.0.1:9092 # 指定 Kafka Broker 地址，可以设置多个，以逗号分隔
    # Kafka Producer 配置项
    producer:
      acks: 1 # 0-不应答。1-leader 应答。all-所有 leader 和 follower 应答。
      retries: 3 # 发送失败时，重试发送的次数
      key-serializer: org.apache.kafka.common.serialization.StringSerializer # 消息的 key 的序列化
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer # 消息的 value 的序列化
    # Kafka Consumer 配置项
    consumer:
      auto-offset-reset: earliest # 设置消费者分组最初的消费进度为 earliest 。可参考博客 https://blog.csdn.net/lishuangzhe7047/article/details/74530417 理解
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring:
          json:
            trusted:
              packages: com.czy.api.domain
    # Kafka Consumer Listener 监听器配置
    listener:
      missing-topics-fatal: false # 消费监听接口监听的主题不存在时，默认会报错。所以通过设置为 false ，解决报错
  #-------------------------RabbitMq-------------------------
  # RabbitMQ 配置项，对应 RabbitProperties 配置类
  rabbitmq:
    host: 127.0.0.1 # RabbitMQ 服务的地址
    port: 5672 # RabbitMQ 服务的端口
    username: guest # RabbitMQ 服务的账号
    password: guest # RabbitMQ 服务的密码
    template:
      # 对应 RabbitProperties.Retry 类
      retry:
        enabled: true # 开启发送机制
        max-attempts: 3 # 最大重试次数。默认为 3 。
        initial-interval: 1000 # 重试间隔，单位为毫秒。默认为 1000 。
    listener:
      simple:
        # 对应 RabbitProperties.ListenerRetry 类
        retry:
          enabled: true # 开启消费重试机制
          max-attempts: 3 # 最大重试次数。默认为 3 。
          initial-interval: 1000 # 重试间隔，单位为毫秒。默认为 1000 。

  #-------------------------spring cloud-------------------------

  cloud:
    # Nacos 作为注册中心的配置项
    nacos:
      discovery:
        server-addr: 127.0.0.1:8848 # Nacos 服务器地址

# Dubbo 配置项，对应 DubboConfigurationProperties 类
dubbo:
  scan:
    base-packages: com.czy.netty.service # 指定 Dubbo 服务实现类的扫描基准包
  # Dubbo 服务暴露的协议配置，对应 ProtocolConfig Map
  protocols:
    dubbo:
      name: dubbo # 协议名称
      port: -1 # 协议端口，-1 表示自增端口，从 20880 开始
  # Dubbo 服务注册中心配置，对应 RegistryConfig 类
  registry:
    address: spring-cloud://127.0.0.1:8848 # 指定 Dubbo 服务注册中心的地址
  # Spring Cloud Alibaba Dubbo 专属配置项，对应 DubboCloudProperties 类
  cloud:
    subscribed-services: '' # 设置订阅的应用列表，默认为 * 订阅所有应用。
#-------------------------Netty-------------------------
netty:
  port: 30020
  debug: false

#-------------------------Logging-------------------------

logging:
  level:
    org:
      springframework:
        kafka: ERROR # spring-kafka INFO 日志太多了，所以我们限制只打印 ERROR 级别
      apache:
        kafka: ERROR # kafka INFO 日志太多了，所以我们限制只打印 ERROR 级别